# -*- coding: utf-8 -*-
"""DataCorrectionFinal2.1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1namd2oSagol9iX5bMY01jyILhzvp9XUM
"""

# Commented out IPython magic to ensure Python compatibility.
#import important packages
# %matplotlib inline
from google.colab import drive
drive.mount('/content/drive')
import numpy as np
from astropy.io import fits
from astropy.stats import sigma_clipped_stats
import matplotlib.pyplot as plt
import glob
import os
from astropy import visualization as aviz
from astropy.nddata.blocks import block_reduce
from astropy.nddata.utils import Cutout2D
from astropy import units as u
from pathlib import Path
from astropy.nddata import CCDData
from astropy.visualization import hist
import shutil
from itertools import chain

#change path here
curpath =  "/content/drive/MyDrive/ColabNotebooks/data/2023-09-04"

# 0. define Important functions
def loadImages(folder_name):
    folder_path = os.path.join(curpath, folder_name)
    image_list = glob.glob(os.path.join(folder_path, '*.fit')) + glob.glob(os.path.join(folder_path, '*.fits'))
    num_files = len(image_list)
    print('Found %d files in %s' % (num_files, folder_name))
    target_size = 2048
    images = np.zeros((target_size, target_size, num_files),dtype=np.int16) #int16 because orignial files are in int16
    # use binning to compress larger images (e.g. 4096) to 2048
    for i in range(num_files):
        with fits.open(image_list[i]) as hdul:
            naxis1 = hdul[0].header.get('NAXIS1', -1) #get size information from the header
            naxis2 = hdul[0].header.get('NAXIS2', -1)
            if naxis1 == target_size and naxis2 == target_size:
                images[:, :, i] = hdul[0].data
            elif naxis1 > 0 and naxis2 > 0:
                binning_factor = max(naxis1 // target_size, naxis2 // target_size)
                binned_data = hdul[0].data.reshape(naxis2 // binning_factor, binning_factor, naxis1 // binning_factor, binning_factor).mean(1).mean(2)
                images[:, :, i] = binned_data
            hdul.close()
    return images
#flatImages = loadImages('FLAT') # Example usage


def show_image(image,
               percl=99, percu=None, is_mask=False,
               figsize=(10, 10),
               cmap='gray', log=False, clip=True,
               show_colorbar=True, show_ticks=True,
               fig=None, ax=None, input_ratio=None):
    if percu is None: # determine percentile range of the stretch
        percu = percl
        percl = 100 - percl
    if (fig is None and ax is not None) or (fig is not None and ax is None):
        raise ValueError('Must provide both "fig" and "ax" '
                         'if you provide one of them')
    elif fig is None and ax is None:
        if figsize is not None:
            image_aspect_ratio = image.shape[0] / image.shape[1]
            figsize = (max(figsize) * image_aspect_ratio, max(figsize))
        fig, ax = plt.subplots(1, 1, figsize=figsize)
    fig_size_pix = fig.get_size_inches() * fig.dpi
    ratio = (image.shape // fig_size_pix).max()
    if ratio < 1:
        ratio = 1
    ratio = input_ratio or ratio
    reduced_data = block_reduce(image, ratio)
    if not is_mask:
         reduced_data = reduced_data / ratio**2
    extent = [0, image.shape[1], 0, image.shape[0]]
    if log:
        stretch = aviz.LogStretch()
    else:
        stretch = aviz.LinearStretch()
    norm = aviz.ImageNormalize(reduced_data,
                               interval=aviz.AsymmetricPercentileInterval(percl, percu),
                               stretch=stretch, clip=clip)
    if is_mask:
        reduced_data = reduced_data > 0
        scale_args = dict(vmin=0, vmax=1)
    else:
        scale_args = dict(norm=norm)
    im = ax.imshow(reduced_data, origin='lower',
                   cmap=cmap, extent=extent, aspect='equal', **scale_args)
    if show_colorbar:
        fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
    if not show_ticks:
        ax.tick_params(labelbottom=False, labelleft=False, labelright=False, labeltop=False)

# 1. Bias
biasImages=loadImages('BIAS')
masterBias = np.median(biasImages, axis=2).astype(np.int16)

#2. Dark
darkImages = loadImages('DARK')
darkImages -= masterBias[:, :, np.newaxis]

darkPath = os.path.join(curpath, 'DARK')
darkFiles = [file for file in os.listdir(darkPath) if file.endswith('.fit') or file.endswith('fits')]
masterDarkFrames = {}  # Dictionary to store master dark frames

for i, fits_file in enumerate(darkFiles):
    fits_path = os.path.join(darkPath, fits_file)
    hdul = fits.open(fits_path)
    header = hdul[0].header
    exptime = header['EXPTIME']

    # Check if the data is a valid array
    if isinstance(darkImages[:, :, i], np.ndarray) and darkImages[:, :, i].shape != ():
        if exptime not in masterDarkFrames:
            masterDarkFrames[exptime] = [darkImages[:, :, i]]
        else:
            masterDarkFrames[exptime].append(darkImages[:, :, i])
    hdul.close()

for exptime, dark_frames in masterDarkFrames.items():
    masterDarkFrames[exptime] = np.median(dark_frames, axis=0)


#3. Flat
flatImages = loadImages('FLAT')

flatPath = os.path.join(curpath, 'FLAT')
flatFiles = [file for file in os.listdir(flatPath) if file.endswith('.fit') or file.endswith('fits')]
masterFlatFrames = {}  # Dictionary to store master flat frames

for i, fits_file in enumerate(flatFiles):
    fits_path = os.path.join(flatPath, fits_file)
    hdul = fits.open(fits_path)
    header = hdul[0].header
    filter_value = header['FILTER']
    # Check if the data is a valid array
    if isinstance(flatImages[:, :, i], np.ndarray) and flatImages[:, :, i].shape != ():
        if filter_value not in masterFlatFrames:
            masterFlatFrames[filter_value] = [flatImages[:, :, i]]
        else:
            masterFlatFrames[filter_value].append(flatImages[:, :, i])
    hdul.close()

# Calculate the median for each master flat frame
for filter_value, flat_frames in masterFlatFrames.items():
    masterFlatFrames[filter_value] = np.median(flat_frames, axis=0)
# Normalize the master flat frames
for filter_value, master_flat in masterFlatFrames.items():
    masterFlatFrames[filter_value] /= np.median(master_flat)

#check everything
for filter_value, master_flat in masterFlatFrames.items():
    print(f"flats Filter: {filter_value}")
for exptime, master_dark in masterDarkFrames.items():
    print(f"darks Exposure Time: {exptime}")

#4. Image correction
# Create a list for light images and header as tuple
lightPath = os.path.join(curpath, 'LIGHT')
lightFiles = [file for file in os.listdir(lightPath) if file.endswith('.fit') or file.endswith('.fits')]
lightsCor= []
lightsRaw =[]

for fits_file in lightFiles:
    fits_path = os.path.join(lightPath, fits_file)
    hdul = fits.open(fits_path)
    header = hdul[0].header
    image = hdul[0].data
    exptime = header['EXPTIME']
    filter_value = header['FILTER']

    # Perform image corrections and store the corrected image
    nearest_exptime_master_dark = min(masterDarkFrames.keys(), key=lambda x: abs(x - exptime))
    masterDarkFrame = masterDarkFrames[nearest_exptime_master_dark]
    correction_factor = exptime / nearest_exptime_master_dark  # dark should have the same exptime as light
    if filter_value not in masterFlatFrames: #just skip image if there is no flat with same filter
        continue
    masterFlat = masterFlatFrames[filter_value]
    corrected_image = (image - masterBias - masterDarkFrame * correction_factor) / masterFlat
    #Store image and its header in new list:
    cor_tuple=(corrected_image,hdul[0].header)
    raw_tuple=(image,hdul[0].header)
    lightsCor.append(cor_tuple) #[objectnumber][0:image, 1:header] so header from 3. pic: lightsCor[2][1]
    lightsRaw.append(raw_tuple)
    hdul.close()

print(len(lightsCor),len(lightsRaw))
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))
show_image(lightsRaw[0][0], ax=ax1, fig=fig)
ax1.set_title('Raw Image')
show_image(lightsCor[0][0], ax=ax2, fig=fig)
ax2.set_title('Corrected Image')
plt.show()

# Saving the files with filter value in the header and title
output_path = os.path.join(curpath, "lightCor")
#shutil.rmtree(output_path)  # Remove if already exists
if not os.path.exists(output_path):
    os.makedirs(output_path)
num_saved_files = 0
for i in range (len(lightsCor)):
    imageCor=lightsCor[i][0].astype(np.int16)
    headerCor=lightsCor[i][1]
    filename = f"lightCor_{headerCor['OBJECT']}_{headerCor['FILTER']}_{headerCor['EXPTIME']}s_{i}.fit"
    fits_path = os.path.join(output_path, filename)
    hdu = fits.PrimaryHDU(imageCor, header=headerCor)  # Use the stored header
    hdul = fits.HDUList([hdu])
    hdul.writeto(fits_path, overwrite=True)
    hdul.close()
    num_saved_files += 1
    if num_saved_files %10 == 0:
       print(num_saved_files)

print(f"Number of files saved: {num_saved_files}")

